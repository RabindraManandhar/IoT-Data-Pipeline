groups:
  - name: kafka_alerts
    rules:
      - alert: KafkaBrokerDown
        expr: up{job=~"kafka-broker-.*"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Kafka broker is down"
          description: "Kafka broker {{ $labels.instance }} has been down for more than 1 minute."

      - alert: KafkaHighLatency
        expr: kafka_server_request_handler_avg_idle_percent < 0.2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Kafka broker high latency"
          description: "Kafka broker {{ $labels.instance }} has high request latency."

      - alert: KafkaUnderReplicatedPartitions
        expr: kafka_server_replica_manager_under_replicated_partitions > 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Kafka under-replicated partitions"
          description: "Kafka broker {{ $labels.instance }} has {{ $value }} under-replicated partitions."

  - name: timescaledb_alerts
    rules:
      - alert: TimescaleDBDown
        expr: up{job="timescaledb"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "TimescaleDB is down"
          description: "TimescaleDB has been down for more than 1 minute."

      - alert: TimescaleDBHighConnections
        expr: pg_stat_database_numbackends > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "TimescaleDB high connection usage"
          description: "TimescaleDB connection usage is {{ $value }}."

  - name: mqtt_alerts
    rules:
      - alert: MQTTBrokerDown
        expr: up{job="mosquitto"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "MQTT broker is down"
          description: "MQTT broker has been down for more than 1 minute."

  - name: application_alerts
    rules:
      - alert: ApplicationDown
        expr: up{job=~"ruuvitag-adapter|kafka-consumer|timescaledb-sink"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Application service is down"
          description: "Service {{ $labels.job }} at {{ $labels.instance }} has been down for more than 2 minutes."

      - alert: HighErrorRate
        expr: rate(iot_messages_failed_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High application error rate"
          description: "Service {{ $labels.job }} has error rate of {{ $value }} errors/sec."

  - name: system_alerts
    rules:
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage on {{ $labels.instance }} is {{ $value }}%."

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage on {{ $labels.instance }} is {{ $value }}%."

  - name: test_alerts
    rules:
      - alert: TestAlert
        expr: vector(1)  # This always returns 1, so always fires
        for: 0s
        labels:
          severity: info
        annotations:
          summary: "Manual test"
          description: "This test alert should always fire to verify the pipeline"