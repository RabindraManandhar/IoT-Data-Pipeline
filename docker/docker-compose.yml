services:
  # Kafka Broker

  kafka1:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka-broker-1
    hostname: kafka1
    ports:
      - "9092:9092" # Internal Kafka port for broker-to-client communication
      - "29092:29092" # Host-accessible external kafka port for host machine tools like Kafka UI 
    environment:
      # KRaft settings - Unique ID and roles
      KAFKA_NODE_ID: ${KAFKA_NODE_ID_1:-1}
      KAFKA_PROCESS_ROLES: ${KAFKA_PROCESS_ROLES:-broker,controller} # This node will act as both broker and controller
      # Define all controllers (all 3 brokers) in the quorum (format: node_id@host:controller_port)
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-1@kafka1:29093,2@kafka2:29093,3@kafka3:29093}

      # Listener Configuration - critical for proper networking      
      # 1. PLAINTEXT - For client communication
      # 2. CONTROLLER - For controller communication
      # 3. PLAINTEXT_HOST - For external access from host machine
      # Listeners for different roles: 'internal docker dns,internal controller port,exposed port for outside-Docker clients'
      KAFKA_LISTENERS: ${KAFKA_LISTENERS_1:-PLAINTEXT://kafka1:9092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:29092}
      # What the broker advertises to clients: 'internal communication,external docker host communication'
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS_1:-PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:29092}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:-CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_INTER_BROKER_LISTENER_NAME:-PLAINTEXT} # Used for broker-to-broker communication
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_CONTROLLER_LISTENER_NAMES:-CONTROLLER} # Controller listener name
      
      # Topic configurations with higher replication factor for fault tolerance
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_MIN_ISR:-2}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      
      # KRaft Cluster Initialization
      CLUSTER_ID: ${CLUSTER_ID} # UUID used to uniquely initialize the KRaft metadata quorum

    volumes:
      - kafka1_data:/var/lib/kafka/data # Persist Kafka logs and data
      - ../src/config/config.yaml:/etc/kafka/config.yaml # Mount configuration file
    networks:
      - kafka-net # Connects to custom Docker network for inter-service DNS
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka1:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka2:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka-broker-2
    hostname: kafka2
    ports:
      - "9093:9092" # Internal Kafka port for broker-to-client communication
      - "29093:29092" # Host-accessible external kafka port for host machine tools like Kafka UI 
    environment:
      # KRaft settings - Unique ID and roles
      KAFKA_NODE_ID: ${KAFKA_NODE_ID_2:-2}
      KAFKA_PROCESS_ROLES: ${KAFKA_PROCESS_ROLES:-broker,controller} # This node will act as both broker and controller
      # Define all controllers (all 3 brokers) in the quorum (format: node_id@host:controller_port)
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-1@kafka1:29093,2@kafka2:29093,3@kafka3:29093}

      # Listener Configuration - critical for proper networking      
      # 1. PLAINTEXT - For client communication
      # 2. CONTROLLER - For controller communication
      # 3. PLAINTEXT_HOST - For external access from host machine
      # Listeners for different roles: 'internal docker dns,internal controller port,exposed port for outside-Docker clients'
      KAFKA_LISTENERS: ${KAFKA_LISTENERS_2:-PLAINTEXT://kafka2:9092,CONTROLLER://kafka2:29093,PLAINTEXT_HOST://0.0.0.0:29092}
      # What the broker advertises to clients: 'internal communication,external docker host communication'
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS_2:-PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:29093}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:-CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_INTER_BROKER_LISTENER_NAME:-PLAINTEXT} # Used for broker-to-broker communication
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_CONTROLLER_LISTENER_NAMES:-CONTROLLER} # Controller listener name
      
      # Topic configurations with higher replication factor for fault tolerance
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_MIN_ISR:-2}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      
      # KRaft Cluster Initialization
      CLUSTER_ID: ${CLUSTER_ID} # UUID used to uniquely initialize the KRaft metadata quorum

    volumes:
      - kafka2_data:/var/lib/kafka/data # Persist Kafka logs and data
      - ../src/config/config.yaml:/etc/kafka/config.yaml # Mount configuration file
    networks:
      - kafka-net # Connects to custom Docker network for inter-service DNS
    depends_on:
      - kafka1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka2:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka3:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka-broker-3
    hostname: kafka3
    ports:
      - "9094:9092" # Internal Kafka port for broker-to-client communication
      - "29094:29092" # Host-accessible external kafka port for host machine tools like Kafka UI
    environment:
      # KRaft settings - Unique ID and roles
      KAFKA_NODE_ID: ${KAFKA_NODE_ID_3:-3}
      KAFKA_PROCESS_ROLES: ${KAFKA_PROCESS_ROLES:-broker,controller} # This node will act as both broker and controller
      # Define all controllers (all 3 brokers) in the quorum (format: node_id@host:controller_port)
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:-1@kafka1:29093,2@kafka2:29093,3@kafka3:29093}

      # Listener Configuration - critical for proper networking      
      # 1. PLAINTEXT - For client communication
      # 2. CONTROLLER - For controller communication
      # 3. PLAINTEXT_HOST - For external access from host machine
      # Listeners for different roles: 'internal docker dns,internal controller port,exposed port for outside-Docker clients'
      KAFKA_LISTENERS: ${KAFKA_LISTENERS_3:-PLAINTEXT://kafka3:9092,CONTROLLER://kafka3:29093,PLAINTEXT_HOST://0.0.0.0:29092}
      # What the broker advertises to clients: 'internal communication,external docker host communication'
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_ADVERTISED_LISTENERS_3:-PLAINTEXT://kafka3:9092,PLAINTEXT_HOST://localhost:29094}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:-CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_INTER_BROKER_LISTENER_NAME:-PLAINTEXT} # Used for broker-to-broker communication
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_CONTROLLER_LISTENER_NAMES:-CONTROLLER} # Controller listener name
      
      # Topic configurations with higher replication factor for fault tolerance
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_MIN_ISR:-2}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_REPLICATION_FACTOR:-3}
      
      # KRaft Cluster Initialization
      CLUSTER_ID: ${CLUSTER_ID} # UUID used to uniquely initialize the KRaft metadata quorum

    volumes:
      - kafka3_data:/var/lib/kafka/data # Persist Kafka logs and data
      - ../src/config/config.yaml:/etc/kafka/config.yaml # Mount configuration file
    networks:
      - kafka-net # Connects to custom Docker network for inter-service DNS
    depends_on:
      - kafka1
      - kafka2
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka3:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5 

# Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:7.9.0
    container_name: schema-registry
    hostname: schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${SCHEMA_REGISTRY_BOOTSTRAP_SERVERS:-kafka1:9092,kafka2:9092,kafka3:9092}
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

      # Schema compatibility settings
      SCHEMA_REGISTRY_AVRO_COMPATIBILITY_LEVEL: ${SCHEMA_COMPATIBILITY_LEVEL:-BACKWARD}

      # Replication factor for schemas topic
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: ${SCHEMA_REGISTRY_REPLICATION_FACTOR:-3}

    volumes:
      - ../src/config/config.yaml:/etc/schema-registry/config.yaml # Mount configuration file
    restart: always
    command: >
      bash -c '
        echo "Waiting for Kafka to be ready..."
        cub kafka-ready -b kafka1:9092 1 60 &&
        cub kafka-ready -b kafka2:9092 1 60 &&
        cub kafka-ready -b kafka3:9092 1 60 &&
        echo "Kafka is ready! Starting Schema Registry..." &&
        /etc/confluent/docker/run
      '
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    
  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080" # Web UI exposed at http://localhost:8080
    environment:
      KAFKA_CLUSTERS_0_NAME: ${KAFKA_UI_CLUSTER_NAME:-local-cluster}
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka1:9092,kafka2:9092,kafka3:9092} # Connects to Kafka's exposed port
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: ${SCHEMA_REGISTRY_URL:-http://schema-registry:8081}
      SERVER_SERVLET_CONTEXT_PATH: / # Root path for the UI
    volumes:
      - ../src/config/config.yaml:/etc/kafka-ui/config.yaml # Mount configuration file
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
    networks:
      - kafka-net # Access Kafka over Docker network

  # TimeScaleDB Database
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: timescaledb
    hostname: timescaledb
    ports:
    - "5432:5432"
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-iot_data}
      POSTGRES_USER: ${POSTGRES_USER:-iot_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-iot_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
      # TimescaleDB specific configurations
      TIMESCALEDB_TELEMETRY: "off"
    volumes:
        - timescaledb_data:/var/lib/postgresql/data
        - ../database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - kafka-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-iot_user} -d ${POSTGRES_DB:-iot_data}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
      
  # MQTT Broker for ESP32 Gateway
  mosquitto:
    image: eclipse-mosquitto:2.0
    container_name: mosquitto
    ports:
      - "1883:1883" # MQTT port
      - "9001:9001" # WebSockets port
    volumes:
      - mosquitto_data:/mosquitto/data
      - mosquitto_log:/mosquitto/log
      - ../mqtt/config:/mosquitto/config
    networks:
      - kafka-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mosquitto_sub", "-t", "$$"]
      interval: 30s
      timeout: 10s
      retries: 3

  # RuuviTag Adapter Service (Replaces the original producer)
  ruuvitag-adapter:
    build:
      context: ..
      dockerfile: docker/Dockerfile.ruuvitag_adapter
    container_name: ruuvitag-adapter
    hostname: ruuvitag-adapter
    volumes:
      - ../src/config/config.yaml:/app/config.yaml # Mount configuration file
    environment:
      PYTHONUNBUFFERED: 1
      # Add debugging environment variables
      PYTHONTRACEMALLOC: 1
      PYTHONFAULTHANDLER: 1
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - mosquitto
    networks:
      - kafka-net
    restart: unless-stopped

  # Kafka Consumer
  kafka-consumer:
    build:
      context: .. # Project root directory
      dockerfile: docker/Dockerfile.consumer
    container_name: kafka-consumer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka1:9092,kafka2:9092,kafka3:9092} # Kafka broker inside Docker network
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME:-iot-sensor-data} # Topic to subscribe and consume from
      KAFKA_CONSUMER_GROUP_ID: ${KAFKA_CONSUMER_GROUP_ID:-iot-data-consumer} # Consumer's group id
      KAFKA_AUTO_OFFSET_RESET: ${KAFKA_AUTO_OFFSET_RESET:-earliest} # Start from the beginning if no offset is found
      # Schema Registry configuration
      SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL:-http://schema-registry:8081}
      PYTHONUNBUFFERED: 1
      CONFIG_FILE_PATH: /app/config.yaml # Path to the config file inside the container
    volumes:
      - ../src/config/config.yaml:/app/config.yaml # Mount configuration file
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - ruuvitag-adapter # Wait until ruuvitag-adapter is available
    networks:
      - kafka-net
  
  # TImeScaleDB Data Sink Service
  timescaledb-sink:
    build:
      context: ..
      dockerfile: docker/Dockerfile.timescaledb_sink
    container_name: timescaledb-sink
    hostname: timescaledb-sink
    environment:
      # Database configuration
      POSTGRES_HOST: timescaledb
      POSTGRES_PORT: 5432
      POSTGRES_DB: ${POSTGRES_DB:-iot_data}
      POSTGRES_USER: ${POSTGRES_USER:-iot_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-iot_password}

      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka1:9092,kafka2:9092,kafka3:9092}
      KAFKA_TOPIC_NAME: ${KAFKA_TOPIC_NAME:-iot-sensor-data}
      DATA_SINK_CONSUMER_GROUP_ID: ${DATA_SINK_CONSUMER_GROUP_ID:-iot-data-sink}
      
      # Schema Registry configuration
      SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL:-http://schema-registry:8081}
      
      # Data sink specific configuration
      DATA_SINK_BATCH_SIZE: ${DATA_SINK_BATCH_SIZE:-50}
      DATA_SINK_COMMIT_INTERVAL: ${DATA_SINK_COMMIT_INTERVAL:-5.0}
      DATA_SINK_MAX_RETRIES: ${DATA_SINK_MAX_RETRIES:-3}
      DATA_SINK_RETRY_BACKOFF: ${DATA_SINK_RETRY_BACKOFF:-2.0}
      
      # TimescaleDB specific settings
      TIMESCALE_BATCH_SIZE: ${TIMESCALE_BATCH_SIZE:-100}
      TIMESCALE_COMMIT_INTERVAL: ${TIMESCALE_COMMIT_INTERVAL:-5.0}
      TIMESCALE_CHUNK_TIME_INTERVAL: ${TIMESCALE_CHUNK_TIME_INTERVAL:-1 day}
      TIMESCALE_COMPRESS_AFTER: ${TIMESCALE_COMPRESS_AFTER:-7 days}
      TIMESCALE_DROP_AFTER: ${TIMESCALE_DROP_AFTER:-90 days}
      
      CONFIG_FILE_PATH: /app/config.yaml
      PYTHONUNBUFFERED: 1
    volumes:
      - ../src/config/config.yaml:/app/config.yaml
    depends_on:
      - timescaledb
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - ruuvitag-adapter
    networks:
      - kafka-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import psycopg2; psycopg2.connect(host=\"timescaledb\", database=\"iot_data\", user=\"iot_user\", password=\"iot_password\")'"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

# Docker Volume for Kafka Storage
volumes:
  kafka1_data:
    driver: local
  kafka2_data:
    driver: local
  kafka3_data:
    driver: local
  schema-registry:
    driver: local
  kafka-ui:
    driver: local
  timescaledb_data:
    driver: local
  mosquitto_data:
    driver: local
  mosquitto_log:
    driver: local
  ruuvitag-adapter:
    driver: local
  kafka-consumer:
    driver: local
  timescaledb-sink:
    driver: local

# Docker Network for All Services
networks:
  kafka-net:
    driver: bridge
    name: docker_kafka-net # Custom bridge network (shared DNS for all services)