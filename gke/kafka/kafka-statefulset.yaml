# GKE-Optimized Kafka StatefulSet with KRaft mode

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: iot-pipeline
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app: kafka
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9101"
    spec:
      # Set security context for the pod: allow group write for mounted volume
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
        runAsNonRoot: true

      # Anti-affinity to spread pods across nodes
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - kafka
              topologyKey: kubernetes.io/hostname
      
      # Init container for storage formatting
      initContainers:
      - name: kafka-init
        image: confluentinc/cp-kafka:7.9.0
        command:
        - sh
        - -exc
        - |
          NODE_ID=${POD_NAME##*-}
          echo "Initializing Kafka storage for node ${NODE_ID}"
          
          # Remove lost+found directory if it exists
          if [ -d /var/lib/kafka/data/lost+found ]; then
            echo "Removing lost+found directory..."
            rm -rf /var/lib/kafka/data/lost+found
          fi

          if [ -f /var/lib/kafka/data/meta.properties ]; then
            echo "Storage already formatted, skipping format step"
          else
            echo "Formatting storage for KRaft mode..."
            cat > /tmp/server.properties <<EOF
          process.roles=broker,controller
          node.id=${NODE_ID}
          controller.quorum.voters=0@kafka-0.kafka-headless.iot-pipeline.svc.cluster.local:9093,1@kafka-1.kafka-headless.iot-pipeline.svc.cluster.local:9093,2@kafka-2.kafka-headless.iot-pipeline.svc.cluster.local:9093
          listeners=PLAINTEXT://:9092,CONTROLLER://:9093
          advertised.listeners=PLAINTEXT://${POD_NAME}.kafka-headless.iot-pipeline.svc.cluster.local:9092
          controller.listener.names=CONTROLLER
          log.dirs=/var/lib/kafka/data
          EOF
            
            kafka-storage format \
              --cluster-id="${CLUSTER_ID}" \
              --config=/tmp/server.properties \
              --ignore-formatted
            
            echo "Storage formatting complete"
          fi
        env:
        - name: CLUSTER_ID
          valueFrom:
            secretKeyRef:
              name: iot-pipeline-secrets
              key: CLUSTER_ID
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      
      # Main Kafka container
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.9.0
        ports:
        - containerPort: 9092
          name: kafka
        - containerPort: 9093
          name: controller
        - containerPort: 7071
          name: jmx
        command:
        - sh
        - -exc
        - |
          # Unset deprecated PORT variable
          unset PORT
          unset KAFKA_PORT

          # Export cluster and node identifiers
          export NODE_ID=${POD_NAME##*-}
          export KAFKA_NODE_ID=${NODE_ID}
          export KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${POD_NAME}.kafka-headless.iot-pipeline.svc.cluster.local:9092
          export KAFKA_CONTROLLER_QUORUM_VOTERS="0@kafka-0.kafka-headless.iot-pipeline.svc.cluster.local:9093,1@kafka-1.kafka-headless.iot-pipeline.svc.cluster.local:9093,2@kafka-2.kafka-headless.iot-pipeline.svc.cluster.local:9093"
          
          # Verify storage is formatted
          if [ ! -f /var/lib/kafka/data/meta.properties ]; then
            echo "ERROR: Storage not formatted! Init container may have failed."
            exit 1
          fi

          echo "Starting Kafka node ${NODE_ID} in KRaft mode..."
          echo "Advertised Listeners: ${KAFKA_ADVERTISED_LISTENERS}"
          echo "Controller Quorum: ${KAFKA_CONTROLLER_QUORUM_VOTERS}"
          
          # Start Kafka using Confluent's entrypoint
          exec /etc/confluent/docker/run
        env:
        - name: CLUSTER_ID
          valueFrom:
            secretKeyRef:
              name: iot-pipeline-secrets
              key: CLUSTER_ID
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_PROCESS_ROLES
          value: "broker,controller"
        - name: KAFKA_CONTROLLER_LISTENER_NAMES
          value: "CONTROLLER"
        - name: KAFKA_LISTENERS
          value: PLAINTEXT://:9092,CONTROLLER://:9093
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "PLAINTEXT"
        - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
          value: "2"
        - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS
          value: "3000"
        - name: KAFKA_NUM_PARTITIONS
          value: "6"
        - name: KAFKA_LOG_RETENTION_MS
          value: "604800000"
        - name: KAFKA_LOG_CLEANUP_POLICY
          value: "delete"
        - name: KAFKA_LOG_DIRS
          value: "/var/lib/kafka/data"
        - name: KAFKA_JMX_PORT
          value: "7071"
        - name: KAFKA_HEAP_OPTS
          value: "-Xmx1G -Xms1G"
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "true"
        # Disable Java DNS caching
        - name: KAFKA_OPTS
          value: "-Dnetworkaddress.cache.ttl=0 -Dnetworkaddress.cache.negative.ttl=0"
        # Explicitly unset PORT to avoid conflicts
        - name: PORT
          value: ""
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "3Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - sh
            - -c
            - ps aux | grep -q "[k]afka.Kafka" || exit 1
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
        readinessProbe:
          exec:
            command:
            - sh
            - -c
            - nc -z localhost 9092 || exit 1
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 5
      
      # JMX Exporter sidecar
      - name: jmx-exporter
        image: bitnami/jmx-exporter:latest
        ports:
        - containerPort: 9101
          name: metrics
        args:
        - "9101"
        - /etc/jmx-exporter/config.yml
        volumeMounts:
        - name: jmx-config
          mountPath: /etc/jmx-exporter/config.yml
          subPath: kafka-jmx-config.yml
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      
      volumes:
      - name: jmx-config
        configMap:
          name: kafka-jmx-config
  
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
      labels:
        app: kafka
    spec:
      accessModes:
      - ReadWriteOnce
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 50Gi


